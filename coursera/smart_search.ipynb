{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Overview",
   "id": "6d4276f61499b8ba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Imagine you are working on a project that involves processing a large collection of text documents, such as research papers, legal documents, or customer service logs. Your task is to develop a system that can quickly retrieve the most relevant segments of text based on a user's query. Traditional keyword-based search methods might not be sufficient, as they often fail to capture the nuanced meanings and contexts within the documents. To address this challenge, you can use different types of retrievers based on LangChain.\n",
    "\n",
    "Using retrievers is crucial for several reasons:\n",
    "\n",
    "- **Efficiency:** Retrievers enable fast and efficient retrieval of relevant information from large datasets, saving time and computational resources.\n",
    "- **Accuracy:** By leveraging advanced retrieval techniques, these tools can provide more accurate and contextually relevant results compared to traditional search methods.\n",
    "- **Versatility:** Different retrievers can be tailored to specific use cases, making them adaptable to various types of text data and query requirements.\n",
    "- **Context awareness:** Some retrievers, such as the Parent Document Retriever, can consider the broader context of the document, enhancing the relevance of the retrieved segments."
   ],
   "id": "6dbbb3d0916891dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/EUODrOFxvSSNL935zpwh9A/retriever.png\" width=\"100%\" alt=\"retriever\"/>",
   "id": "ebcb8838e7e5943"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this lab, you will be able to:\n",
    "\n",
    "- Use various types of retrievers to efficiently extract relevant document segments from text, leveraging LangChain's capabilities.\n",
    "- Apply the Vector Store-backed Retriever to solve problems involving semantic similarity and relevance in large text datasets.\n",
    "- Utilize the Multi-Query Retriever to address situations where multiple query variations are needed to capture comprehensive results.\n",
    "- Implement the Self-Querying Retriever to automatically generate and refine queries, enhancing the accuracy of information retrieval.\n",
    "- Employ the Parent Document Retriever to maintain context and relevance by considering the broader context of the parent document."
   ],
   "id": "b105c9165b74d04f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T03:49:45.453747Z",
     "start_time": "2025-08-06T03:49:45.449968Z"
    }
   },
   "cell_type": "markdown",
   "source": "## Vector Store-Backed Retriever",
   "id": "a997195cf7b56ebd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "A vector store retriever is a type of retriever that utilizes a vector store to fetch documents. It acts as a lightweight wrapper around the vector store class, enabling it to conform to the retriever interface. This retriever leverages the search methods implemented by the vector store, such as similarity search and Maximum Marginal Relevance (MMR), to query texts stored within it.\n",
    "\n",
    "[Link to original doc](https://python.langchain.com/docs/how_to/vectorstore_retriever/)<br>\n",
    "https://python.langchain.com/docs/tutorials/qa_chat_history/#langsmith\n",
    "\n",
    "# How to use a vectorstore as a retriever\n",
    "A vector store retriever is a retriever that uses a vector store to retrieve documents. It is a lightweight wrapper around the vector store class to make it conform to the retriever interface. It uses the search methods implemented by a vector store, like similarity search and MMR, to query the texts in the vector store.\n",
    "\n",
    "In this guide we will cover:\n",
    "\n",
    "1. How to instantiate a retriever from a vectorstore;\n",
    "2. How to specify the search type for the retriever;\n",
    "3. How to specify additional search parameters, such as threshold scores and top-k.\n",
    "\n",
    "# Creating a retriever from a vectorstore\n",
    "You can build a retriever from a vectorstore using its [.as_retriever](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStore.html#langchain_core.vectorstores.base.VectorStore.as_retriever) method. Let's walk through an example.\n",
    "\n",
    "First we instantiate a vectorstore. We will use an in-memory [FAISS](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.faiss.FAISS.html) vectorstore:"
   ],
   "id": "d463ad89cbad637c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T04:32:19.529378Z",
     "start_time": "2025-08-06T04:32:18.487238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"state_of_the_union_2.txt\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)"
   ],
   "id": "6893bb2de1eba630",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can then instantiate a retriever:",
   "id": "abd56b127a43346"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T04:33:58.471408Z",
     "start_time": "2025-08-06T04:33:58.465794Z"
    }
   },
   "cell_type": "code",
   "source": "retriever = vectorstore.as_retriever()",
   "id": "2f034c40073c4829",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This creates a retriever (specifically a [VectorStoreRetriever](https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.base.VectorStoreRetriever.html)), which we can use in the usual way:",
   "id": "c3684264fc452b53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T04:35:24.334658Z",
     "start_time": "2025-08-06T04:35:23.728326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "docs = retriever.invoke(\"what did the president say about ketanji brown jackson?\")\n",
    "docs[]"
   ],
   "id": "cf5a04170cbd8364",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c417dbfb-d6c6-401b-8e01-d140262fd06d', metadata={'source': 'state_of_the_union_2.txt'}, page_content='One of the most serious constitutional responsibilities a President has is nominating someone to serve on the United States Supreme Court. \\n\\nAnd I did that 4 days ago, when I nominated Circuit Court of Appeals Judge Ketanji Brown Jackson. One of our nationâ€™s top legal minds, who will continue Justice Breyerâ€™s legacy of excellence. \\n\\nA former top litigator in private practice. A former federal public defender. And from a family of public school educators and police officers. A consensus builder. Since sheâ€™s been nominated, sheâ€™s received a broad range of supportâ€”from the Fraternal Order of Police to former judges appointed by Democrats and Republicans. \\n\\nAnd if we are to advance liberty and justice, we need to secure the Border and fix the immigration system. \\n\\nWe can do both. At our border, weâ€™ve installed new technology like cutting-edge scanners to better detect drug smuggling.  \\n\\nWeâ€™ve set up joint patrols with Mexico and Guatemala to catch more human traffickers.'),\n",
       " Document(id='477c6802-52f5-43a3-8fad-d074c7036181', metadata={'source': 'state_of_the_union_2.txt'}, page_content='My administration is providing assistance with job training and housing, and now helping lower-income veterans get VA care debt-free.  \\n\\nOur troops in Iraq and Afghanistan faced many dangers. \\n\\nOne was stationed at bases and breathing in toxic smoke from â€œburn pits\" that incinerated wastes of warâ€”medical and hazard material, jet fuel, and more. \\n\\nWhen they came home, many of the worldâ€™s fittest and best trained warriors were never the same. \\n\\nHeadaches. Numbness. Dizziness. \\n\\nA cancer that would put them in a flag-draped coffin. \\n\\nI know. \\n\\nOne of those soldiers was my son Major Beau Biden. \\n\\nWe donâ€™t know for sure if a burn pit was the cause of his brain cancer, or the diseases of so many of our troops. \\n\\nBut Iâ€™m committed to finding out everything we can. \\n\\nCommitted to military families like Danielle Robinson from Ohio. \\n\\nThe widow of Sergeant First Class Heath Robinson.  \\n\\nHe was born a soldier. Army National Guard. Combat medic in Kosovo and Iraq.'),\n",
       " Document(id='2e26bf55-135f-45c9-aebf-9bd1d5d13b5f', metadata={'source': 'state_of_the_union_2.txt'}, page_content='So what are we waiting for? Letâ€™s get this done. And while youâ€™re at it, confirm my nominees to the Federal Reserve, which plays a critical role in fighting inflation.  \\n\\nMy plan will not only lower costs to give families a fair shot, it will lower the deficit. \\n\\nThe previous Administration not only ballooned the deficit with tax cuts for the very wealthy and corporations, it undermined the watchdogs whose job was to keep pandemic relief funds from being wasted. \\n\\nBut in my administration, the watchdogs have been welcomed back. \\n\\nWeâ€™re going after the criminals who stole billions in relief money meant for small businesses and millions of Americans.  \\n\\nAnd tonight, Iâ€™m announcing that the Justice Department will name a chief prosecutor for pandemic fraud. \\n\\nBy the end of this year, the deficit will be down to less than half what it was before I took office.  \\n\\nThe only president ever to cut the deficit by more than one trillion dollars in a single year.'),\n",
       " Document(id='55808e00-e2df-4639-adaa-9a2c1fca0895', metadata={'source': 'state_of_the_union_2.txt'}, page_content='To our fellow Ukrainian Americans who forge a deep bond that connects our two nations we stand with you. \\n\\nPutin may circle Kyiv with tanks, but he will never gain the hearts and souls of the Ukrainian people. \\n\\nHe will never extinguish their love of freedom. He will never weaken the resolve of the free world. \\n\\nWe meet tonight in an America that has lived through two of the hardest years this nation has ever faced. \\n\\nThe pandemic has been punishing. \\n\\nAnd so many families are living paycheck to paycheck, struggling to keep up with the rising cost of food, gas, housing, and so much more. \\n\\nI understand. \\n\\nI remember when my Dad had to leave our home in Scranton, Pennsylvania to find work. I grew up in a family where if the price of food went up, you felt it. \\n\\nThatâ€™s why one of the first things I did as President was fight to pass the American Rescue Plan.  \\n\\nBecause people were hurting. We needed to act, and we did.')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T04:32:22.988275Z",
     "start_time": "2025-08-06T04:32:20.470764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a sample vectorDB\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load blog post\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(data)\n",
    "\n",
    "# VectorDB\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)"
   ],
   "id": "6337ab4f89f9d877",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[Link to original doc](https://python.langchain.com/docs/how_to/MultiQueryRetriever/#simple-usage)\n",
    "\n",
    "Simple usage<br>\n",
    "Specify the LLM to use for query generation, and the retriever will do the rest."
   ],
   "id": "d556de3c926eec1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T03:23:19.321017Z",
     "start_time": "2025-08-06T03:23:17.619021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(), llm=llm\n",
    ")"
   ],
   "id": "f400a7410247130b",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T03:24:21.305989Z",
     "start_time": "2025-08-06T03:24:21.298579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ],
   "id": "5fcb591e84a27d3a",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T03:25:04.673325Z",
     "start_time": "2025-08-06T03:24:59.884676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_docs = retriever_from_llm.invoke(question)\n",
    "len(unique_docs)"
   ],
   "id": "a23163b6445c332",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What are the methods used for Task Decomposition?', 'How can Task Decomposition be achieved?', 'What strategies are employed in Task Decomposition?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that the underlying queries generated by the [retriever](https://python.langchain.com/docs/concepts/retrievers/) are logged at the INFO level.\n",
    "\n",
    "Supplying your own prompt\n",
    "Under the hood, <code>MultiQueryRetriever</code> generates queries using a specific [prompt](https://python.langchain.com/api_reference/langchain/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html).\n",
    "\n",
    "To customize this prompt:<br>\n",
    "1. Make a [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html) with an input variable for the question;<br>\n",
    "2. Implement an [output parser](https://python.langchain.com/docs/concepts/output_parsers/) like the one below to split the result into a list of queries.\n",
    "\n",
    "The prompt and output parser together must support the generation of a list of queries.\n",
    "\n"
   ],
   "id": "821219f63a5bbfa4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T03:29:28.173671Z",
     "start_time": "2025-08-06T03:29:28.142928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Output parser will split the LLM result into a list of queries\n",
    "class LineListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Output parser for a list of lines.\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return list(filter(None, lines))  # Remove empty lines\n",
    "\n",
    "\n",
    "output_parser = LineListOutputParser()\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from a vector\n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search.\n",
    "    Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Chain\n",
    "llm_chain = QUERY_PROMPT | llm | output_parser\n",
    "\n",
    "# Other inputs\n",
    "question = \"What are the approaches to Task Decomposition?\""
   ],
   "id": "c20608b19448ebe",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### API Reference: [BaseOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.base.BaseOutputParser.html) | [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html)",
   "id": "47b50d52b2c8dcef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T03:31:19.492421Z",
     "start_time": "2025-08-06T03:31:15.885926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run\n",
    "retriever = MultiQueryRetriever(\n",
    "    retriever=vectordb.as_retriever(), llm_chain=llm_chain, parser_key=\"lines\"\n",
    ")  # \"lines\" is the key (attribute name) of the parsed output\n",
    "\n",
    "# Results\n",
    "unique_docs = retriever.invoke(\"What does the course say about regression?\")\n",
    "len(unique_docs)"
   ],
   "id": "deba8c4c8c373cf6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide insights from the course on regression analysis?', '2. How is regression discussed in the course material?', '3. What topics related to regression are covered in the course?', '4. What information does the course offer about regression techniques?', '5. In what ways does the course address the topic of regression?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1383d891c4b54ff9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
