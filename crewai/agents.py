
"""
AI Agents Senior Researcher — LangChain + LangGraph

What this does
- Builds a ReAct-style research agent using LangGraph's prebuilt helper
- Uses Tavily search as the internet_search tool
- Steers the agent with a research persona/prompt

Prereqs
pip install -U langchain langchain-community langgraph tavily-python openai
export TAVILY_API_KEY=...  # https://app.tavily.com
export OPENAI_API_KEY=...  # or swap to another Chat model provider per LangChain docs

Run
python ai_agents_researcher_langgraph.py
"""
# Code generated by ChatGPT5

from __future__ import annotations

from langchain_tavily import TavilySearch
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent

# -------------------------------
# 1) Define the research persona
# -------------------------------
research_instructions = (
    "You are an expert researcher. Your job is to conduct thorough research, "
    "and then write a polished report. You have a tool called `internet_search` "
    "that searches the web for a given query. When you use it, prefer recent "
    "sources (last 12–18 months) and extract concrete facts with proper names, "
    "dates, and brief quotes. Always end with a concise summary of pros & cons."
)

# -------------------------------
# 2) Tools (internet_search)
# -------------------------------
# TavilySearchResults returns a list of search results with {url, content}
# Docs: https://python.langchain.com/docs/integrations/tools/tavily
internet_search = TavilySearch(max_results=5, name="internet_search")

# -------------------------------
# 3) LLM
# -------------------------------
# You can replace with any ChatModel supported by LangChain (Groq, Anthropic, etc.)
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

# -------------------------------
# 4) Build the LangGraph ReAct Agent
# -------------------------------
# `state_modifier` injects the persona system prompt into every turn.
agent_graph = create_react_agent(llm, tools=[internet_search], state_modifier=research_instructions)

# -------------------------------
# 5) Run a task end-to-end
# -------------------------------
if __name__ == "__main__":
    task = (
        "Identify the next big trend in AI Agents with pros and cons. "
        "Start by searching for 'emerging AI agent technologies 2024 trends'."
    )

    # You can add more turns here if you want an interactive session; this is a simple one-shot.
    final_state = agent_graph.invoke({
        "messages": [
            {"role": "user", "content": task},
        ]
    })

    # Print the full reasoning transcript (tool calls + answers)
    print("\n===== Conversation Trace =====\n")
    for msg in final_state["messages"]:
        role = msg.get("role", "assistant")
        content = msg.get("content", "")
        if isinstance(content, list):
            # Tool invocations may come back as list chunks; flatten for display
            content = "\n".join([c.get("text", str(c)) if isinstance(c, dict) else str(c) for c in content])
        print(f"[{role}]\n{content}\n")

    # Print the final answer only
    print("\n===== Final Answer =====\n")
    last_msg = [m for m in final_state["messages"] if m.get("role") == "assistant"][-1]
    print(last_msg.get("content", ""))

    # Optional: run more queries programmatically
    # next_state = agent_graph.invoke({
    #     "messages": [
    #         {"role": "user", "content": "Now focus on multi-agent systems vs large action models; compare."},
    #     ]
    # })
    # print(next_state["messages"][-1]["content"])
